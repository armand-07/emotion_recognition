preprocessing:
  random_seed: 33
  orig_datasets: ["affectnet"]
  train_split: 0.8 # val size split would be 1 - train_split
  continuous_format: "cartesian"

training:
  random_seed: 33 #seed for reproducibility
  daug_p_value: 0.5
  daug_horizontalflip: True
  daug_shiftscalerotate: True
  daug_coarsedropout: True
  daug_colorjitter: True
  daug_gaussnoise: True
  image_norm: "ImageNet"

  distillation : False 
  alpha: 0.5
  decaying_strategy: 0
  embedding_method: "both"
  arch: "vit" # architecture name
  teacher_arch: "efficientnet_b2"
  pretraining: "imagenet"
  batch_size: 224 # training and valid batch size
  epoch_samples: original # number of samples considered as one epoch, if None, the whole dataset length is considered
  weighted_sampler_train: False
  weighted_sampler_val: False
  weighted_loss: True
  label_smoothing: 0.0

  lr: '1e-7' # learning rate
  momentum: 0.9 # SGD momentum, for SGD only
  optimizer: 'adamw' # optimization method: sgd | adam
  epochs: 30  # maximum number of epochs to train
  patience: 5 # how many epochs of no loss improvement should we wait before stop training


eval:
  random_seed: 33
  arch: "efficientnet_b0"
  image_norm: "affectnet"
  weights: "affectnet_cat_emot"


inference:
  wandb_id_emotion_model: "comic-sweep-22"
  face_detector_size: "nano"
  face_threshold: 0.65
  tracking: True
  postprocessing: "temporal_average"
  window_size: 3
  distilled_model_out_method: "both" # only used in distilled models
  show_mean_emotion_distrib: True
  save_result: True
  show_inference: False