{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model architecture analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary\n",
    "\n",
    "\n",
    "# To add src to the path so that we can import modules\n",
    "current_directory = os.getcwd()\n",
    "if not current_directory.endswith(\"emotion_recognition\"):\n",
    "    sys.path.append(os.path.join(current_directory, 'emotion_recognition'))\n",
    "\n",
    "try:\n",
    "    from src import NUMBER_OF_EMOT\n",
    "except ModuleNotFoundError:\n",
    "    print(\"Ensure that src is added to PATH and restart the kernel\")\n",
    "    print(sys.path)\n",
    "\n",
    "# Take GPU\n",
    "if not torch.cuda.is_available():\n",
    "       raise RuntimeError(\"Enable GPU support\")\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.56\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 384.62\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(weights = \"DEFAULT\").to(device)\n",
    "print(summary(model, (3, 224, 224))) # Summary of the model with input size (3, 224, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We try changing last FC layer in order to adapt to our task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(2048, NUMBER_OF_EMOT)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size is compatible with layer sizes.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model(torch.rand((1, 3, 224, 224)).to(device))\n",
    "    print(\"Image size is compatible with layer sizes.\")\n",
    "except RuntimeError as e:\n",
    "    e = str(e)\n",
    "    if e.endswith(\"Output size is too small\"):\n",
    "        print(\"Image size is too small.\")\n",
    "    elif \"shapes cannot be multiplied\" in e:\n",
    "        required_shape = e[e.index(\"x\") + 1:].split(\" \")[0]\n",
    "        print(f\"Linear layer needs to have size: {required_shape}\")\n",
    "    else:\n",
    "        print(f\"Error not understood: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNext50_32x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnext50_32x4d-1a0047aa.pth\" to /home/usuaris/imatge/armand.de.asis/.cache/torch/hub/checkpoints/resnext50_32x4d-1a0047aa.pth\n",
      "100%|██████████| 95.8M/95.8M [00:03<00:00, 29.2MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5          [-1, 128, 56, 56]           8,192\n",
      "       BatchNorm2d-6          [-1, 128, 56, 56]             256\n",
      "              ReLU-7          [-1, 128, 56, 56]               0\n",
      "            Conv2d-8          [-1, 128, 56, 56]           4,608\n",
      "       BatchNorm2d-9          [-1, 128, 56, 56]             256\n",
      "             ReLU-10          [-1, 128, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          32,768\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-18          [-1, 128, 56, 56]             256\n",
      "             ReLU-19          [-1, 128, 56, 56]               0\n",
      "           Conv2d-20          [-1, 128, 56, 56]           4,608\n",
      "      BatchNorm2d-21          [-1, 128, 56, 56]             256\n",
      "             ReLU-22          [-1, 128, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          32,768\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-28          [-1, 128, 56, 56]             256\n",
      "             ReLU-29          [-1, 128, 56, 56]               0\n",
      "           Conv2d-30          [-1, 128, 56, 56]           4,608\n",
      "      BatchNorm2d-31          [-1, 128, 56, 56]             256\n",
      "             ReLU-32          [-1, 128, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          32,768\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 256, 56, 56]          65,536\n",
      "      BatchNorm2d-38          [-1, 256, 56, 56]             512\n",
      "             ReLU-39          [-1, 256, 56, 56]               0\n",
      "           Conv2d-40          [-1, 256, 28, 28]          18,432\n",
      "      BatchNorm2d-41          [-1, 256, 28, 28]             512\n",
      "             ReLU-42          [-1, 256, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-50          [-1, 256, 28, 28]             512\n",
      "             ReLU-51          [-1, 256, 28, 28]               0\n",
      "           Conv2d-52          [-1, 256, 28, 28]          18,432\n",
      "      BatchNorm2d-53          [-1, 256, 28, 28]             512\n",
      "             ReLU-54          [-1, 256, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-60          [-1, 256, 28, 28]             512\n",
      "             ReLU-61          [-1, 256, 28, 28]               0\n",
      "           Conv2d-62          [-1, 256, 28, 28]          18,432\n",
      "      BatchNorm2d-63          [-1, 256, 28, 28]             512\n",
      "             ReLU-64          [-1, 256, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-70          [-1, 256, 28, 28]             512\n",
      "             ReLU-71          [-1, 256, 28, 28]               0\n",
      "           Conv2d-72          [-1, 256, 28, 28]          18,432\n",
      "      BatchNorm2d-73          [-1, 256, 28, 28]             512\n",
      "             ReLU-74          [-1, 256, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 512, 28, 28]         262,144\n",
      "      BatchNorm2d-80          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-81          [-1, 512, 28, 28]               0\n",
      "           Conv2d-82          [-1, 512, 14, 14]          73,728\n",
      "      BatchNorm2d-83          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-84          [-1, 512, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 512, 14, 14]         524,288\n",
      "      BatchNorm2d-92          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-93          [-1, 512, 14, 14]               0\n",
      "           Conv2d-94          [-1, 512, 14, 14]          73,728\n",
      "      BatchNorm2d-95          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-96          [-1, 512, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-102          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-103          [-1, 512, 14, 14]               0\n",
      "          Conv2d-104          [-1, 512, 14, 14]          73,728\n",
      "     BatchNorm2d-105          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-106          [-1, 512, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-112          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-113          [-1, 512, 14, 14]               0\n",
      "          Conv2d-114          [-1, 512, 14, 14]          73,728\n",
      "     BatchNorm2d-115          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-116          [-1, 512, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-122          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-123          [-1, 512, 14, 14]               0\n",
      "          Conv2d-124          [-1, 512, 14, 14]          73,728\n",
      "     BatchNorm2d-125          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-126          [-1, 512, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-132          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-133          [-1, 512, 14, 14]               0\n",
      "          Conv2d-134          [-1, 512, 14, 14]          73,728\n",
      "     BatchNorm2d-135          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-136          [-1, 512, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141         [-1, 1024, 14, 14]       1,048,576\n",
      "     BatchNorm2d-142         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-143         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-144           [-1, 1024, 7, 7]         294,912\n",
      "     BatchNorm2d-145           [-1, 1024, 7, 7]           2,048\n",
      "            ReLU-146           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153           [-1, 1024, 7, 7]       2,097,152\n",
      "     BatchNorm2d-154           [-1, 1024, 7, 7]           2,048\n",
      "            ReLU-155           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-156           [-1, 1024, 7, 7]         294,912\n",
      "     BatchNorm2d-157           [-1, 1024, 7, 7]           2,048\n",
      "            ReLU-158           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163           [-1, 1024, 7, 7]       2,097,152\n",
      "     BatchNorm2d-164           [-1, 1024, 7, 7]           2,048\n",
      "            ReLU-165           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-166           [-1, 1024, 7, 7]         294,912\n",
      "     BatchNorm2d-167           [-1, 1024, 7, 7]           2,048\n",
      "            ReLU-168           [-1, 1024, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,028,904\n",
      "Trainable params: 25,028,904\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 361.78\n",
      "Params size (MB): 95.48\n",
      "Estimated Total Size (MB): 457.83\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = models.resnext50_32x4d(weights = \"DEFAULT\").to(device)\n",
    "print(summary(model, (3, 224, 224))) # Summary of the model with input size (3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(2048, NUMBER_OF_EMOT)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size is compatible with layer sizes.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model(torch.rand((1, 3, 224, 224)).to(device))\n",
    "    print(\"Image size is compatible with layer sizes.\")\n",
    "except RuntimeError as e:\n",
    "    e = str(e)\n",
    "    if e.endswith(\"Output size is too small\"):\n",
    "        print(\"Image size is too small.\")\n",
    "    elif \"shapes cannot be multiplied\" in e:\n",
    "        required_shape = e[e.index(\"x\") + 1:].split(\" \")[0]\n",
    "        print(f\"Linear layer needs to have size: {required_shape}\")\n",
    "    else:\n",
    "        print(f\"Error not understood: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
